{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prosyslab/sigpl23-tutorial/blob/main/1_Concepts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 환경설정하기"
      ],
      "metadata": {
        "id": "IC-upOpwnQ8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. GPU 사용 설정\n",
        "메뉴 바에서 [런타임] -> [런타임 유형 변경] -> [하드웨어 가속기] 항목에서 GPU 선택\n",
        "\n",
        "※ Colab GPU 하루 최대 12시간까지 사용 가능\n"
      ],
      "metadata": {
        "id": "uZzOtYQiDPNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 한글 설정\n",
        "\n",
        "주의: 아래 apt-get 설치 코드가 현재 런타임에는 바로 반영되지 않을 수 있습니다.\n",
        "아래 코드 셀을 실행한 뒤 [런타임] -> [런타임 다시 시작] 을 통해 설치된 패키지가 현재 실행 환경에 반영되도록 해주세요."
      ],
      "metadata": {
        "id": "_Mr8NUV0-cti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "id": "4YtZhTaN-eXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ],
      "metadata": {
        "id": "gGAZEy0A-i15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 라이브러리 설치하기"
      ],
      "metadata": {
        "id": "mN7IlHVCff2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch transformers datasets"
      ],
      "metadata": {
        "id": "krbSJqrrnEav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 편집기 설정\n",
        "메뉴 바에서 [도구] -> [설정] -> [편집기] 에서 \"행 번호 표시\" 와 \"들여쓰기 가이드 표시\" 등 유용한 기능을 설정하세요."
      ],
      "metadata": {
        "id": "A2ZQk44ciRBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다국어 BERT (mBERT) 의 Attention 점수 확인하기\n"
      ],
      "metadata": {
        "id": "RtRSJp4srq6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 허브에서 모델 다운로드하기\n",
        "* Hugging Face model hub: https://huggingface.co/bert-base-multilingual-cased"
      ],
      "metadata": {
        "id": "GZ4PWnoRuei3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")"
      ],
      "metadata": {
        "id": "RLj6pMF4F-hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")"
      ],
      "metadata": {
        "id": "UPvmyL1-XOAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문장 토크나이즈 해보기"
      ],
      "metadata": {
        "id": "3vHUkt34nifP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = \"가는 말이 고와야 오는 말도 곱다\"\n",
        "tokens = tokenizer.tokenize(example_text, add_special_tokens=True)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "for token, token_id in zip(tokens, token_ids):\n",
        "  print(f\"{token:>3} :: {token_id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07gyXSamnhz5",
        "outputId": "3c760ff9-eec2-4928-d1a4-1c95566c1b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] :: 101\n",
            "  가 :: 8843\n",
            "##는 :: 11018\n",
            "  말 :: 9251\n",
            "##이 :: 10739\n",
            "  고 :: 8888\n",
            "##와 :: 12638\n",
            "##야 :: 21711\n",
            "  오 :: 9580\n",
            "##는 :: 11018\n",
            "  말 :: 9251\n",
            "##도 :: 12092\n",
            "  곱 :: 8894\n",
            "##다 :: 11903\n",
            "[SEP] :: 102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 토크나이저의 사전\n",
        "* 토크나이저의 사전은 학습 데이터에 등장하는 단어 통계를 학습한 결과물입니다.\n",
        "* 아래 예시 문장을 토크나이즈하여 학습 데이터에서 발견되지 않은 단어와 더 많이 발견된 단어를 확인해보세요."
      ],
      "metadata": {
        "id": "Uq7J5P3cggx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = \"동해물과 백두산이 마르고 닳도록\"\n",
        "# 토크나이저 호출해보기\n",
        "\n",
        "example_text = \"나 보기가 역겨워 가실 때에는\"\n",
        "# 토크나이저 호출해보기"
      ],
      "metadata": {
        "id": "DNDR1uy6ga6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 구조 확인\n",
        "* BERT 모델 구조 사용\n",
        "* 모델에 입력할수 있는 토큰 최대 길이: 512\n",
        "* Embeddings Layer + 12 x Encoder Layer + Pooler Layer\n",
        "  * Embeddings Layer: 119,547 -> 768\n",
        "  * 12 x Encoder Layer: 768 -> 768\n",
        "  * Pooler Layer: 768 -> 768"
      ],
      "metadata": {
        "id": "mxJH3v2hLAIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(repr(model.config))\n",
        "print(repr(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W5E_AGzK2TA",
        "outputId": "ef9c98f5-2a94-492d-e2ae-01f7002774ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.31.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 크기 계산해서 `pytorch_model.bin` 크기와 비교해보기\n",
        "\n",
        "* 파라미터 개수 구하기\n",
        "* 파라미터 크기 확인\n",
        "  * `torch.float16` -> 개당 2 byte\n",
        "  * `torch.float32` -> 개당 4 byte\n",
        "* 파라미터 개수 x 파라미터 크기 = 모델의 최소 크기\n",
        "  * mBERT: 178M * 4byte = 711 MB\n",
        "  * `pytorch_model.bin` 크기와 거의 동일\n",
        "\n",
        "(참고) mixed precision 사용하는 경우도 있음"
      ],
      "metadata": {
        "id": "-fJmpuw8GWBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type_params = set([t.dtype for t in model.parameters()])\n",
        "type_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NkaD2M0H00E",
        "outputId": "c93a29d1-2d57-4348-c56e-48a94648d2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{torch.float32}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_params = sum(t.numel() for t in model.parameters())\n",
        "print(f\"number of params : {num_params:,}\")\n",
        "print(f\"total param size : {num_params * 4:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rwpGMrzHVG-",
        "outputId": "0adf3e56-235d-4985-e835-aa98bf3f1f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of params : 177,853,440\n",
            "total param size : 711,413,760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mBERT 를 이용한 텍스트 임베딩 생성\n"
      ],
      "metadata": {
        "id": "OsU_EXHYXB0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "# 모델과 입력 GPU 메모리에 올리기\n",
        "model = model.to(device)\n",
        "\n",
        "example_text = \"가는 말이 고와야 오는 말도 곱다\"\n",
        "tokenized_inputs = tokenizer(example_text, return_tensors='pt')\n",
        "\n",
        "input_ids = tokenized_inputs.input_ids.to(device)\n",
        "attention_mask = tokenized_inputs.attention_mask.to(device)\n",
        "\n",
        "# 모델 임베딩\n",
        "model_out = model(input_ids=input_ids, attention_mask=attention_mask, output_attentions=True)"
      ],
      "metadata": {
        "id": "W4iCFTZ-Bt1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mBERT 모델의 Attention 점수 확인해보기\n",
        "\n",
        "* 각 층별 Attention 행렬 크기: `batch_size * num_heads  * sequence_length * sequence_length`\n",
        "([참고](https://huggingface.co/docs/transformers/main_classes/output#transformers.modeling_outputs.BaseModelOutput.attentions))\n",
        "* multi-head attention: attention 연산을 병렬화하는 기법\n",
        "* Transformers 의 `ModelOutput` 출력에 달린 `attentions` 는 이미 multi-head attention 에 대한 softmax, weighted average 연산을 마친 값"
      ],
      "metadata": {
        "id": "Qad3v5J2XedR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attns = model_out.attentions\n",
        "len(attns), attns[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvehsz0gXkD5",
        "outputId": "1c7b94b1-fae4-46ed-efd9-f71b1c72a15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, torch.Size([1, 12, 15, 15]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "\n",
        "def plot_attention(attention, tokens):\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  attention = attention[:len(tokens), :len(tokens)]\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + tokens, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + tokens, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')\n",
        "  plt.suptitle('Attention weights')"
      ],
      "metadata": {
        "id": "N6Hrtxlxawy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 마지막 레이어의 attention hitmap 출력하기"
      ],
      "metadata": {
        "id": "akG2zTTRCTAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_idx = -1\n",
        "sum_heads = attns[layer_idx][0, 0, :, :]\n",
        "for head_idx in range(1, model.config.num_attention_heads):\n",
        "  sum_heads = sum_heads + attns[layer_idx][0, head_idx, :, :]\n",
        "plot_attention(sum_heads.cpu().detach().numpy(), tokenizer.tokenize(example_text, add_special_tokens=True))"
      ],
      "metadata": {
        "id": "3-wHxrEqbfni"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}