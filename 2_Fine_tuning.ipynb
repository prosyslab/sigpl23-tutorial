{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "555d17a55cab4d0a9d7585f51e6b1332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9655c68836e349a58460c3bca75aaca5",
              "IPY_MODEL_39963597d10e4858973494d1df4bdf11",
              "IPY_MODEL_4f436e34337c4d39befce57eeb3fefe5"
            ],
            "layout": "IPY_MODEL_8f6e29ca7d0f4d6a9e446216ebc90caf"
          }
        },
        "9655c68836e349a58460c3bca75aaca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf71ce0fc61f481d8b5d4017876559b0",
            "placeholder": "​",
            "style": "IPY_MODEL_799059fd32884d83bd96f285f23fb137",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "39963597d10e4858973494d1df4bdf11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_907560653f014573a332f111fd117383",
            "max": 498627950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8b42fe79c244569a5aec3991497bdd8",
            "value": 498627950
          }
        },
        "4f436e34337c4d39befce57eeb3fefe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41f0e0f727ca4fdc864098933fd5a812",
            "placeholder": "​",
            "style": "IPY_MODEL_31297d0de7464cf88d9a95118222de44",
            "value": " 499M/499M [00:37&lt;00:00, 12.5MB/s]"
          }
        },
        "8f6e29ca7d0f4d6a9e446216ebc90caf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf71ce0fc61f481d8b5d4017876559b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "799059fd32884d83bd96f285f23fb137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "907560653f014573a332f111fd117383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b42fe79c244569a5aec3991497bdd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41f0e0f727ca4fdc864098933fd5a812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31297d0de7464cf88d9a95118222de44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61acf474b57840809e78bf4974d067f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb7ab13a6c6f4e1b93cd3f8dea3a04a3",
              "IPY_MODEL_da0505f709154c33b614ac72a5f6a77a",
              "IPY_MODEL_f729ecf99ea1488f9555f328b637cf15"
            ],
            "layout": "IPY_MODEL_7f7b4c8fb9374ab4b909630b1e931a60"
          }
        },
        "bb7ab13a6c6f4e1b93cd3f8dea3a04a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_710f50035f6e4f43bc387a76f2009b4e",
            "placeholder": "​",
            "style": "IPY_MODEL_ea94e9df41e243dfb1ce69652d68f397",
            "value": "Map: 100%"
          }
        },
        "da0505f709154c33b614ac72a5f6a77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_313b304646fe4d35b36ab4ffafd9ac24",
            "max": 12934,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2616c3acc3ac4dd1b56b31f106c0c7c0",
            "value": 12934
          }
        },
        "f729ecf99ea1488f9555f328b637cf15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d46b9fc593b405680904312c2649f57",
            "placeholder": "​",
            "style": "IPY_MODEL_7fcfb3c2addd40b882978f5facd7fd72",
            "value": " 12934/12934 [02:13&lt;00:00, 156.02 examples/s]"
          }
        },
        "7f7b4c8fb9374ab4b909630b1e931a60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "710f50035f6e4f43bc387a76f2009b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea94e9df41e243dfb1ce69652d68f397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "313b304646fe4d35b36ab4ffafd9ac24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2616c3acc3ac4dd1b56b31f106c0c7c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d46b9fc593b405680904312c2649f57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fcfb3c2addd40b882978f5facd7fd72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prosyslab/sigpl23-tutorial/blob/main/2_Fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 환경설정\n",
        "\n",
        "* 라이브러리 설치\n",
        "* 구글 드라이브 마운트\n",
        "  * 학습 중 약 3GB 데이터가 드라이브에 저장됩니다 여유공간을 확인해주세요\n",
        "* 텐서보드 연결\n",
        "* GPU 연결 확인"
      ],
      "metadata": {
        "id": "w4tT935RvE9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch transformers datasets evaluate accelerate"
      ],
      "metadata": {
        "id": "6GXN_t-vuws5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "home_dir = \"/content/gdrive/MyDrive/Colab-Data\"\n",
        "model_dir = f\"{home_dir}/models/codebert-code-completion\""
      ],
      "metadata": {
        "id": "zydl0qJb23HE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973cab5a-7bcb-4719-c651-33dc0241da7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "yW4EgYeBdP6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir $model_dir"
      ],
      "metadata": {
        "id": "n702os_ddzws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "assert torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "yoS5l_UkGSy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 거대 언어모델 Facebook/Incoder 사용해서 Fine-tuning 없이 코드 자동완성 해보기"
      ],
      "metadata": {
        "id": "a8rUOPfGur6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 허브에서 모델과 토크나이저 가져오기\n",
        "* HuggingFace model hub 에서 오픈 소스 모델 검색해서 가져오기: https://huggingface.co/models\n",
        "\n",
        "주의할 점\n",
        "* 로컬 서버에서 사용할 경우 모델 크기가 서버의 GPU 에 맞을지 확인하세요\n",
        "  * 파라미터 개수 * 4byte * 1.2(실행 비용) < 서버 GPU 메모리 크기\n",
        "* 믿을 수 있는 모델인지 확인하세요. `pytorch_model.bin` 은 파이썬 pickle 형식이라 함부로 로드하면 위험할 수 있습니다."
      ],
      "metadata": {
        "id": "Xd-kNejRvNWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/incoder-1B\")\n",
        "model = model.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/incoder-1B\")\n",
        "\n",
        "example_text = \"\"\"\n",
        "def hello(name):\n",
        "  print(f\"\"\".strip()\n",
        "tokenized_inputs = tokenizer(example_text, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "Fw_aVzAWu5T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 구조 확인하기"
      ],
      "metadata": {
        "id": "Q_vPbECJcp6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구조를 출력해서 mBERT 와 차이점을 확인해보세요"
      ],
      "metadata": {
        "id": "FhmnuL0tc0O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 파라미터 개수를 구해서 로컬에서 실행하려면 메모리 소비량이 얼마나 될지 추산해보세요"
      ],
      "metadata": {
        "id": "RnLZS6xac5rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 자동완성 `model.generate` 기능 호출\n",
        "* `num_beams`: beam search 크기\n",
        "* `repetition_penalty`: 언어모델이 뒤에 오는 토큰을 반복적으로 생성하는 경향이 있습니다. 이를 보정해주는 값입니다.\n",
        "\n",
        "* 코드를 실행한 뒤 실제로 사용한 리소스를 확인해서 앞에서 추산한 값과 비슷한지 확인해봅니다."
      ],
      "metadata": {
        "id": "AK_o9jCnvRIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = \"\"\"\n",
        "def hello(name):\n",
        "  print(f\"\"\".strip()\n",
        "tokenized_inputs = tokenizer(example_text, return_tensors=\"pt\")\n",
        "input_ids = tokenized_inputs.input_ids.to(model.device)\n",
        "generated_ids = model.generate(input_ids, max_length=128, repetition_penalty=0.5, num_beams=5)\n",
        "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "B-quLC-ZvnIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd938e9-4541-4a0b-c461-9927e0b0a6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def hello(name):\n",
            "  print(f'''Hello {name}!''')\n",
            "hello('World')\n",
            "</cell>\n",
            "<cell>\n",
            "def hello(name):\n",
            "  print(f'''Hello {name}!''')\n",
            "hello('World')\n",
            "</cell>\n",
            "<cell>\n",
            "def hello(name):\n",
            "  print(f'''Hello {name}!''')\n",
            "hello('World')\n",
            "</cell>\n",
            "<cell>\n",
            "def hello(name):\n",
            "  print(f'''Hello {name}!''')\n",
            "hello('World')\n",
            "</cell>\n",
            "<cell>\n",
            "def hello(name):\n",
            "  print(f'''Hello {name}!''')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CodeBERT Fine-tuning 학습하기"
      ],
      "metadata": {
        "id": "YUrKSySiU4PY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 토크나이저, 데이터셋, 사전학습된 CodeBERT 모델 준비\n",
        "\n",
        "#### `RobertaLMHeadModel` 모델 구조\n",
        "* Roberta 모델 + Causal Language Model 구조 사용\n",
        "* Embedding Layer + 12 x Encoder Layer + Pooler Layer\n",
        "  * Embedding Layer: batch_size * 514 * 50,265 -> batch_size * 514 * 768\n",
        "  * Encoder Layer: batch_size * 514 * 768 -> batch_size * 514 * 768\n",
        "* LM Layer: batch_size * 514 * 768 -> batch_size * 514\n"
      ],
      "metadata": {
        "id": "eo5PdwYneemy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akwH1LRoU4PZ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\", add_prefix_space=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/codebert-base\", is_decoder=True)\n",
        "print(repr(model))"
      ],
      "metadata": {
        "id": "WqeM7ry0U4PZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904,
          "referenced_widgets": [
            "555d17a55cab4d0a9d7585f51e6b1332",
            "9655c68836e349a58460c3bca75aaca5",
            "39963597d10e4858973494d1df4bdf11",
            "4f436e34337c4d39befce57eeb3fefe5",
            "8f6e29ca7d0f4d6a9e446216ebc90caf",
            "bf71ce0fc61f481d8b5d4017876559b0",
            "799059fd32884d83bd96f285f23fb137",
            "907560653f014573a332f111fd117383",
            "d8b42fe79c244569a5aec3991497bdd8",
            "41f0e0f727ca4fdc864098933fd5a812",
            "31297d0de7464cf88d9a95118222de44"
          ]
        },
        "outputId": "1681596c-e23d-43f4-92c6-6026bf8dc155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "555d17a55cab4d0a9d7585f51e6b1332"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RobertaForCausalLM(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (lm_head): RobertaLMHead(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 파라미터 개수를 구해서 facebook/incoder-1B 모델에 비해 얼마나 작은 모델인지 확인해보세요"
      ],
      "metadata": {
        "id": "WCJ4_THO08m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"code_x_glue_cc_code_completion_token\", \"java\")"
      ],
      "metadata": {
        "id": "XeSJWmiUU4Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리"
      ],
      "metadata": {
        "id": "F0F2WRm_Hy9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(examples):\n",
        "  tokenized_inputs = tokenizer(examples[\"code\"], padding=\"max_length\", truncation=True, is_split_into_words=True, add_special_tokens=False)\n",
        "  labels = tokenized_inputs.input_ids\n",
        "  return dict(labels=labels, **tokenized_inputs)\n",
        "\n",
        "tokenized_datasets = ds.map(tokenize, batched=True)\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "id": "da-rdFvYU4Pa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303,
          "referenced_widgets": [
            "61acf474b57840809e78bf4974d067f7",
            "bb7ab13a6c6f4e1b93cd3f8dea3a04a3",
            "da0505f709154c33b614ac72a5f6a77a",
            "f729ecf99ea1488f9555f328b637cf15",
            "7f7b4c8fb9374ab4b909630b1e931a60",
            "710f50035f6e4f43bc387a76f2009b4e",
            "ea94e9df41e243dfb1ce69652d68f397",
            "313b304646fe4d35b36ab4ffafd9ac24",
            "2616c3acc3ac4dd1b56b31f106c0c7c0",
            "7d46b9fc593b405680904312c2649f57",
            "7fcfb3c2addd40b882978f5facd7fd72"
          ]
        },
        "outputId": "da01d207-41e8-41d6-bc8d-62a387e19173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12934 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61acf474b57840809e78bf4974d067f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'code', 'labels', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 12934\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'code', 'labels', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 7189\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'code', 'labels', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 8268\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 샘플 데이터 준비"
      ],
      "metadata": {
        "id": "kbkPVrGienmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "sample = dict()\n",
        "sample_ratio = 0.1\n",
        "size = round(tokenized_datasets[\"train\"].num_rows * sample_ratio)\n",
        "sample[\"train\"] = tokenized_datasets[\"train\"].shuffle(seed=1234).select(range(size))\n",
        "\n",
        "# validation, test 에대해서도 동일한 방법으로 데이터를 샘플링해 보세요\n",
        "\n",
        "sample_datasets = DatasetDict(sample)\n",
        "sample_datasets.num_rows"
      ],
      "metadata": {
        "id": "L7QlbbQ5U4Pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "436223c6-bc4d-4826-8fd7-fd62b0a180f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 1293, 'test': 1293, 'validation': 1293}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습 설정\n"
      ],
      "metadata": {
        "id": "n88pqmFVeqOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hyper parameters\n",
        "실습에서 사용하는 하이퍼파라미터 외에도 실제로 사용되는 하이퍼파라미터가 많습니다. [공식 문서](https://huggingface.co/docs/transformers/main_classes/trainer)를 참고하세요.\n",
        "\n",
        "* `output_dir`: 모델 저장 위치. 체크포인트, 로그 등 저장\n",
        "* `evaluation_strategy`: 학습 중 `eval_dataset` 을 이용해서 평가하는 단위\n",
        "* `save_strategy`: 저장 단위\n",
        "* `num_train_epochs`: 총 데이터 학습 횟수 지정\n",
        "* `per_device_train_batch_size`: 학습 데이터 배치 크기. 이 크기에 따라 메모리 사용량이 매우 달라집니다.\n",
        "* `gradient_accumulation_steps`: 역전파 단위\n",
        "  * `per_device_train_batch_size * gradient_accumulation_steps` 단위로 역전파되며, 이 크기를 총 `TOTAL_BATCH_SIZE` 라고 부르기도 합니다. 분산 학습일 경우에는 사용하는 GPU 갯수까지 곱해서 사용합니다.\n",
        "  * 하이퍼파라미터에서 `*_steps` 의이름으로 지정되는 값의 경우 1 step 의 크기는 `TOTAL_BATCH_SIZE` 입니다.\n",
        "* `per_device_eval_batch_size`: 학습 중 평가 시 사용하는 데이터 배치 크기.\n",
        "  * 평가 시에는 모델을 업데이트하지 않기 때문에 역전파를 위한 중간 텐서를 유지하지 않고, 따라서 메모리 사용량이 학습 과정에 비해 적습니다. 동일한 메모리를 사용할 때 학습 데이터 배치보다 평가 데이터 배치를 크게 잡을 수 있습니다.\n",
        "* `learning_rate`: gradient step 크기\n",
        "* `lr_scheduler_type`: 학습 중 learning rate 를 바꾸는 방법\n",
        "  * `\"linear\"`: 전체 학습 횟수에 도달할 때까지 선형으로 감소\n",
        "  * `\"constant\"`: 전체 학습 중 일정한 learning rate 유지\n",
        "  * `\"cosine\"`: consine 함수에 따라 learning rate 가 진동\n",
        "  * 이 외 문서 참고\n",
        "* `warmup_ratio`: 학습 초기에 전체 학습 횟수의 `warmup_ratio` 만큼 동안 지정한 `learning_rate` 까지 선형으로 증가하도록 설정\n",
        "  * 학습 초기에는 learning rate 가 너무 크면 로컬 옵티멈에 빠지기 쉽습니다.\n",
        "* `logging_steps`: loss 등의 학습 메트링을 로깅하는 단위\n",
        "  * `gradient_accumulation_steps * logging_steps` 만큼 데이터를 학습한 뒤 로깅합니다."
      ],
      "metadata": {
        "id": "9HKwDf7hgw2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "  output_dir=model_dir,\n",
        "  evaluation_strategy=\"epoch\",\n",
        "  save_strategy=\"epoch\",\n",
        "  num_train_epochs=3.0,\n",
        "  per_device_train_batch_size=8,\n",
        "  gradient_accumulation_steps=32,\n",
        "  per_device_eval_batch_size=16,\n",
        "  learning_rate=2e-5,\n",
        "  lr_scheduler_type=\"linear\",\n",
        "  warmup_ratio=0.1,\n",
        "  logging_steps=1,\n",
        "  seed=1234,\n",
        ")\n"
      ],
      "metadata": {
        "id": "OhKOZWTgJ_Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 샘플 데이터에서 학습해보기"
      ],
      "metadata": {
        "id": "zMcXwUUle6t4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "# 아래 코드를 실행할 때 오류가 생긴다면 데이터 전처리부터 코드를 다시 확인해보세요\n",
        "\n",
        "trainer = Trainer(\n",
        "  model=model,\n",
        "  args=args,\n",
        "  train_dataset=sample_datasets[\"train\"],      # 학습 데이터\n",
        "  eval_dataset=sample_datasets[\"validation\"],  # 평가 데이터\n",
        ")\n",
        "trainer.train(resume_from_checkpoint=None)\n",
        "trainer.save_model(args.output_dir)"
      ],
      "metadata": {
        "id": "ckIVl4OKU4Pb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "2b45df3d-71a7-45b7-efc4-05e8215581ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 13:51, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>14.878500</td>\n",
              "      <td>13.946575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>11.708200</td>\n",
              "      <td>11.368376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>10.770000</td>\n",
              "      <td>10.646372</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트 데이터에서 정확도 검토하기\n",
        "\n",
        "※ 참고: CodeXGLUE 리더보드 https://microsoft.github.io/CodeXGLUE/\n",
        "* CodeXGLUE 벤치마크 평가 시에는 생성 시간에 Beam search 가 적용되어있어 아래 평가식과는 차이가 있습니다.\n",
        "* Beam search 가 적용된 생성 품질을 평가 해보고 싶을 경우 CodeXGLUE 가 제공하는 평가 스크립트 사용해보세요\n",
        "* 일반적으로 Beam search 를 적용해서 Seq2Seq 모델을 학습하고 평가하고싶을 경우 `Seq2SeqTrainer` 를 사용할 수 있습니다.\n",
        "\n",
        "#### 평가식 정의\n",
        "* [accuracy](https://huggingface.co/spaces/evaluate-metric/accuracy)\n",
        "* [bleu](https://huggingface.co/spaces/evaluate-metric/bleu)\n",
        "  * 정답과 예측 문자열이 비슷한 정도 측정"
      ],
      "metadata": {
        "id": "cnTpR1_Q0leA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ],
      "metadata": {
        "id": "0rNsSwObh-ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "predicts = []\n",
        "labels = []\n",
        "ds_test = sample_datasets[\"test\"].remove_columns(\"code\")\n",
        "for batch in DataLoader(ds_test, batch_size=32):\n",
        "  input_ids = torch.stack(batch[\"input_ids\"], dim=1).to(device)\n",
        "  attention_mask = torch.stack(batch[\"attention_mask\"], dim=1).to(device)\n",
        "  with torch.no_grad():\n",
        "    model_out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    batch_preds = torch.argmax(model_out.logits, dim=-1).detach()\n",
        "  batch_labels = torch.stack(batch[\"labels\"], dim=-1)\n",
        "  predicts.extend(batch_preds)\n",
        "  labels.extend(batch_labels)\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "print(accuracy.compute(predictions=torch.concat(predicts), references=torch.concat(labels)))\n",
        "\n",
        "predicts = [tokenizer.decode(pred, skip_special_tokens=True) for pred in predicts]\n",
        "labels = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n",
        "print(bleu.compute(predictions=predicts, references=labels))\n"
      ],
      "metadata": {
        "id": "ZhPEPth-9AbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e82848-7743-450a-ee38-7a53533bd3ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 0.05721160817865429}\n",
            "{'bleu': 0.00032199973851967505, 'precisions': [0.11993234674985417, 0.0007846613011082149, 7.162434463724657e-05, 1.5949344880659027e-06], 'brevity_penalty': 1.0, 'length_ratio': 1.8535143568152639, 'translation_length': 630864, 'reference_length': 340361}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 저장된 모델 읽어서 실행해보기"
      ],
      "metadata": {
        "id": "asSPyo9w7Aq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import RobertaForCausalLM\n",
        "\n",
        "ds_test = tokenized_datasets['test']\n",
        "\n",
        "model = RobertaForCausalLM.from_pretrained(model_dir)\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "EnkjbWZ30jcQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c10e2c82-709f-4afe-ba13-10f0f268b18b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForCausalLM(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): RobertaLMHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex = ds_test[0]\n",
        "model_out = model(\"\"\"모델 입력을 만들어 보세요\"\"\")\n",
        "tokenizer.batch_decode(torch.argmax(model_out.logits, dim=-1).detach(), skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "XPj9lB7W1GdG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}